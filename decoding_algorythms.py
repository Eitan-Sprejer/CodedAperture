"""
This script defines different decoding methods explored: mura, general, and fourier. 
These patterns are generated by the functions defined as 'get_name_decoding_pattern', 
and can be used to decode an image using the functions called 'name_image_reconstruction'. 
The function decode_image is the one that finally decodes the specified image.
"""

import numpy as np
from scipy.ndimage import convolve
from utils import SlitScreen, SensorScreen, Decoder, upsample_image
import scipy as sp
import matplotlib.pyplot as plt


def get_mura_decoding_pattern(slit_mask: np.ndarray):
    """
    Calculates the decoding pattern for a MURA mask.

    Args:
        slit_mask (np.ndarray): The MURA mask.

    Returns:
        np.ndarray: The decoding pattern.
    """
    decoding_pattern = np.zeros_like(slit_mask)
    for i in range(slit_mask.shape[0]):
        for j in range(slit_mask.shape[1]):
            cent_i = int(i - (slit_mask.shape[0] - 1) / 2)
            cent_j = int(j - (slit_mask.shape[1] - 1) / 2)
            # TEMPORARY FIX TO SEE IF THE ELEMENTS ARE IN THE DIAGONAL FOR A NON-SQUARE MATRIX.
            if abs(cent_i + cent_j*slit_mask.shape[0]/slit_mask.shape[1]) < 1:
                decoding_pattern[i, j] = 1
            else:
                if slit_mask[i, j] == 1:
                    decoding_pattern[i, j] = 1
                elif slit_mask[i, j] == 0:
                    decoding_pattern[i, j] = -1
    # Renormalize the decoding pattern for the convolution
    # decoding_pattern = decoding_pattern / np.sum(decoding_pattern)
    return decoding_pattern


def get_general_decoding_pattern(slit_mask: np.ndarray):
    """
    Calculates the decoding pattern for a general mask.

    Args:
        slit_mask (np.ndarray): The general mask.

    Returns:
        np.ndarray: The decoding pattern.
    """
    transparency = np.sum(slit_mask) / (slit_mask.shape[0] * slit_mask.shape[1])
    decoding_pattern = np.zeros_like(slit_mask)
    for i in range(slit_mask.shape[0]):
        for j in range(slit_mask.shape[1]):
            if slit_mask[i, j] == 1:
                decoding_pattern[i, j] = 1
            elif slit_mask[i, j] == 0:
                decoding_pattern[i, j] = transparency / (transparency - 1)
    # Renormalize the decoding pattern for the convolution
    # decoding_pattern = decoding_pattern / np.sum(decoding_pattern)
    return decoding_pattern


def get_fourier_decoding_pattern(
    slit_mask: np.ndarray, image: np.ndarray, threshold: float
):
    """
    Calculates the decoding pattern for a Fourier mask.

    Args:
        slit_mask (np.ndarray): The Fourier mask.
        image (np.ndarray): The image to be reconstructed.
        threshold (float): The threshold value.

    Returns:
        np.ndarray: The decoding pattern.
    """
    slit_mask = slit_mask / np.sum(slit_mask)
    # Pad the slit_mask with 0s so that it matches the size of the image
    slit_mask = np.pad(
        slit_mask,
        (
            (
                image.shape[0] // 2 - slit_mask.shape[0] // 2,
                image.shape[0] // 2 - slit_mask.shape[0] // 2,
            ),
            (
                image.shape[1] // 2 - slit_mask.shape[1] // 2,
                image.shape[1] // 2 - slit_mask.shape[1] // 2,
            ),
        ),
        "constant",
        constant_values=0,
    )
    slit_mask = np.roll(slit_mask, image.shape[0] // 2, axis=0)
    slit_mask = np.roll(slit_mask, image.shape[1] // 2, axis=1)
    if slit_mask.shape != image.shape:
        slit_mask = slit_mask[: image.shape[0], : image.shape[1]]  # temporary solution

    # Fourier transform the image and the slit
    slit_ft = sp.fft.fft2(slit_mask)
    slit_ft_inv = np.conj(slit_ft) / (np.abs(slit_ft) ** 2 + threshold)
    return slit_ft_inv


def apply_upsampling(sensor: SensorScreen, slit: SlitScreen):
    """
    Upsamples the sensor or the slit so that the size to resolution ratio of both
    coinside.
    """
    sensor_size_to_resolution_ratio = sensor.mask_size / sensor.mask_resolution
    slit_size_to_resolution_ratio = slit.mask_size / slit.mask_resolution
    if np.any(sensor_size_to_resolution_ratio > slit_size_to_resolution_ratio):
        # Upsample the sensor
        upsample_scale = sensor_size_to_resolution_ratio / slit_size_to_resolution_ratio
        upsampled_resolution = (sensor.mask_resolution * upsample_scale).astype(int)
        sensor_screen = upsample_image(sensor.screen, new_height=upsampled_resolution[0], new_width=upsampled_resolution[1])

        # Leave the slit as is
        slit_mask = slit.mask
    elif np.any(sensor_size_to_resolution_ratio < slit_size_to_resolution_ratio):
        # Upsample the slit
        upsample_scale = slit_size_to_resolution_ratio / sensor_size_to_resolution_ratio
        upsampled_resolution = (slit.mask_resolution * upsample_scale).astype(int)
        slit_mask = upsample_image(slit.mask, new_height=upsampled_resolution[0], new_width=upsampled_resolution[1])

        # Take the values to 0 and 1
        slit_mask[slit_mask > 0.5] = 1
        slit_mask[slit_mask <= 0.5] = 0

        # Leave the sensor as is
        sensor_screen = sensor.screen
    else:
        sensor_screen = sensor.screen
        slit_mask = slit.mask
    return sensor_screen, slit_mask


def mura_image_reconstruction(sensor: SensorScreen, slit: SlitScreen):
    """
    Reconstructs an image using a MURA mask.

    Args:
        sensor (SensorScreen): The sensor screen.
        slit (SlitScreen): The MURA mask.

    Returns:
        Tuple[np.ndarray, np.ndarray]: The decoding pattern and the reconstructed image.
    """
    # Apply upsampling
    sensor_screen, slit_mask = apply_upsampling(sensor, slit)

    # Calculate the decoding pattern and reconstruct the image.
    decoding_pattern = get_mura_decoding_pattern(slit_mask)
    reconstructed_image = convolve(sensor_screen, decoding_pattern, mode="wrap")
    return decoding_pattern, reconstructed_image


def general_image_reconstruction(sensor: SensorScreen, slit: SlitScreen):
    """
    Reconstructs an image using a general mask.

    Args:
        sensor (SensorScreen): The sensor screen.
        slit (SlitScreen): The general mask.

    Returns:
        Tuple[np.ndarray, np.ndarray]: The decoding pattern and the reconstructed image.
    """
    # Apply upsampling
    sensor_screen, slit_mask = apply_upsampling(sensor, slit)

    # Calculate the decoding pattern and reconstruct the image.
    decoding_pattern = get_general_decoding_pattern(slit_mask)
    reconstructed_image = convolve(sensor_screen, decoding_pattern, mode="wrap")
    return decoding_pattern, reconstructed_image


def fourier_image_reconstruction(
    sensor: SensorScreen, slit: SlitScreen, threshold: float = 1e-2
):
    """
    Reconstructs an image using a Fourier mask.

    Args:
        sensor (SensorScreen): The sensor screen.
        slit (SlitScreen): The Fourier mask.
        threshold (float, optional): The threshold value. Defaults to 1e-2.

    Returns:
        Tuple[np.ndarray, np.ndarray]: The decoding pattern and the reconstructed image.
    """
    sensor_screen, slit_mask = apply_upsampling(sensor, slit)

    decoding_pattern_ft = get_fourier_decoding_pattern(
        slit_mask=slit_mask, image=sensor_screen, threshold=threshold
    )
    sensor_ft = sp.fft.fft2(sensor_screen)
    reconstructed_image_ft = sensor_ft * decoding_pattern_ft
    reconstructed_image = sp.fft.ifft2(reconstructed_image_ft)
    decoding_pattern = sp.fft.ifft2(decoding_pattern_ft)
    # Center back the decoding_pattern
    decoding_pattern = np.roll(decoding_pattern, -sensor_screen.shape[0] // 2, axis=0)
    decoding_pattern = np.roll(decoding_pattern, -sensor_screen.shape[1] // 2, axis=1)

    return np.abs(decoding_pattern), np.abs(reconstructed_image)


def decode_image(
    sensor: SensorScreen, slit: SlitScreen, decoder: Decoder, mask_type: str
):
    """
    Decodes an image using a mask.

    Args:
        sensor (SensorScreen): The sensor screen.
        slit (SlitScreen): The mask.
        decoder (Decoder): The decoder.
        mask_type (str): The type of mask.

    Returns:
        Tuple[np.ndarray, np.ndarray]: The decoding pattern and the reconstructed image.
    """
    if decoder.method == "mura":
        assert (
            mask_type == "mura"
        ), "Mura decoding method can only be used with Mura masks"
        decoding_pattern, reconstructed_image = mura_image_reconstruction(sensor, slit)
    elif decoder.method == "general":
        decoding_pattern, reconstructed_image = general_image_reconstruction(
            sensor, slit
        )
    elif decoder.method == "fourier":
        decoding_pattern, reconstructed_image = fourier_image_reconstruction(
            sensor, slit, threshold=decoder.threshold
        )

    # Flip the reconstructed image
    reconstructed_image = np.flip(reconstructed_image, axis=0)
    reconstructed_image = np.flip(reconstructed_image, axis=1)

    return decoding_pattern, reconstructed_image
